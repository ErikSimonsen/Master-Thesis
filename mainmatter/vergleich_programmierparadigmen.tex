\section {Vergleich reaktive \& imperative Anwendung}
\label{section:vergleich_reaktiv_imperativ}
Um zu prüfen, ob Leistungsfähigkeit und Skalierbarkeit einer reaktiven, auf dem \newline
\verb|Multi-Reactor-Modell| und \verb|Nonblocking I/O| basierenden,
Anwendung tatsächlich die einer traditionellen, auf dem \verb|Thread-per-Request Modell| und \verb|Blocking I/O| basierenden, Anwendung übertrifft, werden in
diesem Kapitel beide Ansätze hinsichtlich verschiedener Metriken in einem festen Zeitintervall miteinander verglichen.

Dafür werden sowohl die reaktive, als auch die nicht-reaktive Anwendung, in 5 Testreihen, jeweils zwei Lasttests unterzogen:
\begin{enumerate}
    \item Abfrage von statischen Daten
    \item Abfrage von dynamischen Daten (mit Datenbankanbindung)
\end{enumerate}
Dabei wird pro Lasttest eine Reihe an Lasten bzw. \textit{workloads} von einem Client-Host generiert und über eine feste Dauer in kleinen Zeitinvervallen
an einen ausgewählten HTTP-Endpunkt der Anwendung gesendet.
In dieser Zeit wird das Zeitinvervall vom Starten der Anwendung bis zur Beantwortung der ersten Anfrage,
der benötigte Arbeitsspeicher und CPU-Auslastung des Prozesses, der Durchsatz, sowie die Latenz gemessen.

Für Container- und Cloud-Umgebungen eignen sich, primär aus Kostengründen, Anwendungen die, statt auf hohen Durchsatz und lange Laufzeiten, auf
schnelle Startzeiten und geringen Ressourcenverbrauch setzen.
Aus diesem Grund werden die beiden Anwendungen sowohl im \textit{JVM mode} als auch im \textit{native mode}
(siehe Absatz \verb|Quarkus und native image| in Kapitel \ref{subsubsec:frameworks})
den beiden Lasttests unterzogen. Ingesamt ergeben sich also 4 Testszenarien pro Anwendung.

\subsection{Implementierung \& Systemaufbau}
\label{section:implementierung}
Die beiden Anwendungen implementieren mit dem Quarkus-Framework jeweils eine simple REST-Schnittstelle mit HTTP-CRUD Methoden
und einer angebundenen PostgreSQL-Datenbank.
Dabei ist vorallem die HTTP-Schicht von Interesse. Die HTTP-Unterstützung von Quarkus basiert auf einem reaktiven, nicht-blockierenden
Unterbau: der Vert.x Engine (siehe Kapitel \ref{subsubsec:reaktive_systeme}).
Jede HTTP-Anfrage wird auf einem der \textit{event-loop threads} bzw. \textit{IO threads}
verarbeitet und durch eine Routing-Schicht an den Anwendungscode weitergeleitet.
Je nachdem welcher Ansatz zur Implementierung des jeweiligen HTTP-Endpunktes gewählt wurde,
wird der abzuarbeitende Code dann auf einem blockierenden \textit{worker thread}, ganz nach dem \verb|Thread-Per-Request Modell|, aus dem
\textit{worker thread pool} (Servlet, \Gls{jaxrsg}(*)) oder, nach dem \verb|Multi-Reactor-Modell|, weiter auf einem der
\textit{IO threads} (Reactive Routes, Reactive Resteasy) ausgeführt.

\newpage
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{Quarkus_HTTP_Layer}
    \caption{Quarkus HTTP-Schicht \parencite{QuarkusReactiveRoutes}}
    \label{fig:quarkus_http_schicht}
\end{figure}

Die \textit{IO threads} sind dafür zuständig alle IO-Operationen asynchron auszuführen und die jeweiligen EventListener bzw. Subscriber
auszulösen sobald die Operationen abgeschlossen sind.
Damit sich beide Anwendungen nahe an einer realen Java-EE CRUD REST-API orientieren, haben
sie (zusätzlich zu den grundlegenden Abhängigkeiten des Quarkus-Frameworks) folgende Projekt-Abhängigkeiten:
\begin{itemize}
    \item JAX-RS Implementierung
    \item \Gls{jsong}(*) Unterstützung
    \item PostgreSQL - Datenbanktreiber
    \item \Gls{jpag}(*) Implementierung
\end{itemize}

Diese Abhängigkeiten wurden vom Quarkus Maven-Repository sowohl in blockierender,
als auch in nicht-blockierender, reaktiver und in \verb|native image|-kompatibler Form bereitgestellt: \parencite{MavenQuarkusIO}
% space between the text and the left/right border of its containing cell is set to 18 pt
\setlength{\tabcolsep}{18pt}
% the height of each row is set to 1.5 relative to its default height
\renewcommand{\arraystretch}{1.5}
\begin{table}[ht!]
    \centering
    \begin{tabular}{| c | c | c |}
        \hline
                         & Blockierend      & Nicht-blockierend (reaktiv) \\
        \hline
        JAX-RS           & Resteasy         & Resteasy Reactive           \\
        \hline
        JSON             & Resteasy-Jackson & Resteasy-Reactive-Jackson   \\
        \hline
        Datenbanktreiber & JDBC-Postgresql  & Reactive-Pg-Client          \\
        \hline
        JPA-/ORM         & Hibernate-ORM    & Hibernate-Reactive          \\
        \hline
    \end{tabular}
    \caption{Tabelle mit den Abhängigkeiten beider Applikationen}
    \label{table:dependencies}
\end{table}

In Listing \ref{lst:update_reactive} und \ref{lst:update_blocking} ist jeweils die Update Methode der REST-APIs abgebildet, um den
Unterschied der beiden Paradigmen auf Code-Ebene darzustellen.

Dabei wird versucht eine Entity mit der übergebenen \verb|id| des API-Endpunktes
aus der Datenbank abzurufen und, falls eine Entity mit der \verb|id| gefunden werden konnte, dessen Name mit dem Wert
aus dem Request-Body der Anfrage zu überschreiben. Anschließend wird die Entity mit dem neuen Namen wieder in die Datenbank zurückgeschrieben
und HTTP-Statuscode 422 an den Client zurückgegeben. Falls keine Entity gefunden werden konnte, wird stattdessen
HTTP-Statuscode 404 zurückgegeben.

In der reaktiven Anwendung ist die gesamte Logik, sowie Fehler- und Nullprüfung in einer einzigen Pipeline abgebildet.
Da in diesem Beispiel Mutiny genutzt wird, wird der Rückgabetyp immer als \verb|Uni| oder \verb|Multi|-Objekt eines spezifischen Typs
angegeben. \verb|Uni| repräsentiert dabei einen Datenstrom der entweder ein Element oder ein Fehler-Event emittiert.
\verb|Multi| repräsentiert einen Datenstrom der entweder 0, 1, \verb|n| oder unendlich viele Elemente emittieren kann.
Der \verb|Subscriber| ist in diesem Fall der Aufrufer der \verb|update|-Methode und sorgt dafür, dass die Pipeline überhaupt ausgeführt wird.

Jede \verb|Pipe| bzw. \verb|Processor| der Pipeline der \verb|update|-Methode gibt ein \verb|Uni|, dieses kann entweder
vom Typ \verb|Void| (für null-Werte) oder von der jeweiligen Entität sein, an den Downstream weiter
\footnote{invoke() und call() sind Abkürzungen, um die Lesbarkeit zu verbessern\parencite{MutinyShortcuts}}.

\begin{lstlisting}[caption=Update Methode der reaktiven Anwendung, language=Java, captionpos=b, label=lst:update_reactive]
@PUT
@Path("{id}")
public Uni<Response> update(Long id, Fruit fruit) {
	if (fruit == null || fruit.getName() == null) {
		return Uni.createFrom().item(Response.status(422).build());
	}
	return fruitRepository.findById(id).onItem()
	.ifNotNull().invoke(storedFruit -> storedFruit.setName(fruit.getName())
	).call(storedFruit -> fruitRepository.update(storedFruit))
			.onItem().ifNotNull().transform(storedFruit ->
			Response.ok(storedFruit).build())
			.onItem().ifNull().continueWith(Response.status(Status.NOT_FOUND).build());
}
\end{lstlisting}
\begin{lstlisting}[caption=Update Methode der nicht-reaktiven Anwendung, language=Java, captionpos=b, label=lst:update_blocking]
@PUT
@Path("/{id}")
public Response update(Fruit fruit, @PathParam("id") Long id) {
	if (fruit == null || fruit.getName() == null) {
		return Response.status(422).build();
	}
	Fruit storedFruit = fruitRepository.findById(id);
	if (storedFruit == null) {
		return Response.status(Response.Status.NOT_FOUND).build();
	}
	storedFruit.setName(fruit.getName());
	fruitRepository.update(storedFruit);
	return Response.status(Response.Status.OK).build();
}
\end{lstlisting}

Der Projekt-Code dieser Arbeit kann von GitHub unter \url{https://github.com/ErikSimonsen/quarkus-iothread-workerpool} eingesehen und abgerufen werden.

\subsection{Testumgebung}
\label{section:testumgebung}
Für die Testumgebung werden zwei Systeme benötigt: der Client-Host und der Server-Host.
Dabei muss es sich um UNIX-Systeme handeln, da einige der verwendeten Werkzeuge nur auf diesen Systemen verfügbar sind.
Zudem müssen beide Systeme per SSH von einem (idealerweise vorhandenem) dritten System, dem User-Host
\footnote{Dies kann allerdings auch der Client-Host selber sein}
erreichbar sein, damit dieses den Testablauf in der korrekten Abfolge ausführen kann.
Der Einfachheit halber empfiehlt es sich, dass sich alle Geräte im gleichen Netzwerk befinden.
Beide Anwendungen verwenden Version 1.12.1 des Quarkus Frameworks, welches wiederrum Version 20.1 der GraalVM nutzt.
Um eine reproduzierbare Anwendungsumgebung und Ressourcenallokation zu ermöglichen, laufen beide Anwendungen auf dem Server-Host in
jeweils einem Docker-Container mit fest definierten Ressourcen:
\begin{itemize}
    \item Nutzung von 4 CPU-Kernen
    \item 1024 MB RAM
    \item 256 MB Heap Größe für den Java-Prozess
          \footnote{Seit Java 10 wird automatisch ~1/4 des Speicher Limits des Containers genutzt \parencite{Java10ReleaseNotes}}
\end{itemize}
Der jeweilige Docker-Container für die Postgresql-Datenbank allokiert:
\begin{itemize}
    \item 4 CPU-Kerne
    \item 2048 MB RAM
\end{itemize}

Die Größe des von Vert.x verwendeten \verb|Worker Thread Pools| (siehe Abbildung \ref{fig:quarkus_http_schicht}) beträgt standardmäßig 20 und bleibt
unverändert, die Größe des \verb|Event-Loop Thread Pools| hingegen wird für die Tests manuell auf 8 gesetzt, da die Anwendung durch die Ressourcenallokation
des Docker-Containers nur 4 CPU-Kerne nutzen darf und jeder dieser CPU-Kerne Hyperthreading unterstützt. \footnote{Wodurch jeder physische CPU-Kern über
    zwei logische CPUs verfügt} Damit kann die optimale Verteilung von einem \verb|Event-Loop Thread| bzw. \verb|IO-Thread| pro
logischer CPU erreicht werden.
Standardmäßig wird die Ressourcenbegrenzung durch Container von Vert.x nicht beachtet und die Anzahl der \verb|Event loop|-Threads auf die doppelte
Anzahl der verfügbaren CPU-Kerne des Container-Hosts gesetzt, weswegen es für ressourcenbegrenzte Container der beschriebenen Korrektur bedarf.
Der \verb|Worker Thread Pool| wird vom \verb|Thread-per-Request Modell| bzw. \verb|Blocking I/O| genutzt, während der \verb|Event-Loop Thread Pool| von der
reaktiven Anwendung bzw. \verb|Nonblocking I/O| genutzt wird.

Die Anwendung, die auf dem Client-Host die \textit{work load} für die beiden zu testenden Anwendungen generiert,
nutzt in dieser Testumgebung 4 Threads.
\footnote{Welche Laufzeitumgebungen und Tools für die Tests auf den jeweiligen Hosts vorhanden sein müssen, und wie diese installiert werden
    wird in der README.md-Datei des Projektverzeichnisses beschrieben.}

Da die Messergebnisse je nach verwendeter Hardware der Client- und Server-Hosts durchaus variieren können werden im Folgenden
die Systemspezifikationen der verwendeten Systeme des Authors gelistet:
\begin{table}[ht!]
    \centering
    \begin{tabular}{| c | c |}
        \hline
        Server-Host                                                  \\
        \hline
        CPU's          & AMD Ryzen 7 2700x eight-core processor x 16 \\
        \hline
        RAM            & 16GB                                        \\
        \hline
        Speicher       & 1,5 TB                                      \\
        \hline
        Betriebssystem & Fedora 34 (Workstation Edition)             \\
        \hline
        Kernel         & Linux version \verb|5.12.14-300.fc34.x86_64|   \\
        \hline
    \end{tabular}
    \caption{Systemspezifikationen der verwendeten Server-Maschine}
    \label{table:system_host}
\end{table}

\begin{table}[ht!]
    \centering
    \begin{tabular}{| c | c |}
        \hline
        Client-Host                                                \\
        Hardware       & Acer Aspire VN7-591G                      \\
        \hline
        CPU            & Intel® Core™ i5-4210H CPU @ 2.90GHz × 4   \\
        \hline
        RAM            & 8GB                                       \\
        \hline
        Speicher       & 500 GB                                    \\
        \hline
        Betriebssystem & Fedora 34 (Workstation Edition)           \\
        \hline
        Kernel         & Linux version \verb|5.12.14-300.fc34.x86_64| \\
        \hline
    \end{tabular}
    \caption{Systemspezifikationen der verwendeten Client-Maschine}
    \label{table:system_client}
\end{table}

\subsection{Testvorgehen / Testaufbau}
\label{section:vorgehen}
Der im Folgenden erläuterte Versuchsaufbau basiert auf einer, vom Autor erweiterten, Architektur die vom Quarkus-Entwicklerteam
zur Erstellung von verschiedenen Benchmarks für den Quarkus Technologie-Stack genutzt wurde.
\parencite{QuarkusBlog, QuarkusJohnaohara}

Um den gesamten Versuchsablauf zu automatisieren und über mehrere Server zu steuern wird ein Tool namens qDup eingesetzt.
Damit können Shell-Kommandos als Skripte gruppiert, und verschiedenen Hosts je nach Rolle zugewiesen werden.
\footnote{Die qDup Skripte mit dem gesamten Testablauf können im Verzeichnis \textit{/scripts/qDup} des Quellcodeverzeichnisses eingesehen und
    angepasst werden.}
Um dem Ablauf korrekt zu steuern werden Signale definiert die ein Host sendet, und auf die die anderen Hosts warten um ihrerseits
weitere Skripte auszuführen.
\footnote{Beispielsweise sollte der Server-Host erst anfangen den Java-Prozess zu überwachen, sobald der Client-Host die \textit{workload}
    generiert und nicht bereits davor}

Wie bereits in \ref{section:testumgebung} angedeutet, nutzt qDup SSH um auf die jeweilige Hosts zuzugreifen.

Im ersten Schritt \textit{build applications} wird auf dem Server-Host das Quellcodeverzeichnis geklont und beide Anwendungen werden, für
ein einfaches Deployment in den Docker-Container, jeweils als \gls{uber-jar}(*) und \verb|native image| gebaut.

Anschließend wird über ein JavaScript-Skript, welches in der Laufzeitumgebung Node.js läuft,
die \verb|Mean Start Time to First Request|, also das durchschnittliche Zeitintervall zwischem dem Start einer Anwendung bis
zur Verarbeitung der ersten Anfrage, mehrfach gemessen und als Textdatei gespeichert.
Dabei wird die gebaute Anwendung, ohne Docker-Container, auf dem Server-Host gestartet und die Zeit genommen. Anschließend werden in einer Schleife
solange Anfragen an einen Endpunkt der Anwendung gestellt bis das Ergebnis ein Statuscode 200 ist, was den Endpunkt der Messung markiert.
Aus den gemessenen Startzeiten wird in der Auswertung der Daten anschließend der Durchschnitt gebildet, um somit die \verb|Mean Start Time to First Request|
der Anwendung zu erhalten.

Darüber hinaus werden die Docker-Container der Datenbank
\footnote{Nur beim Test mit dynamischen Daten} und der beiden REST-APIs gebaut.

Beim zweiten Schritt \textit{run applications} wird der Docker-Container der jeweiligen Anwendung gestartet und anschließend signalisiert,
dass die Anwendung nun bereit ist.
Daraufhin wird auf dem Client-Host das Skript \textit{generate load} gestartet.
Die \textit{workload} ist hier definiert als die Anzahl der, an den Server-Host, versendeten \textit{HTTP-Anfragen pro Sekunde}.
Für das Generieren und Übermitteln der \textit{workload} wird das Werkzeug \textit{wrk2} genutzt, welches das
bewährte HTTP-Benchmarking Tool \textit{wrk} um folgende Funktionen erweitert:
\begin{enumerate}
    \item Konstanter \textit{workload} Durchsatz
    \item Korrekteres Messverfahren der Antwort-Latenz durch Vermeidung von \verb|Coordinated Omission|
    \item Hochexaktes Messen durch \Glsuseri{hdrHistogramm}(*)
\end{enumerate}\parencite{Wrk2, Wrk}

\paragraph{Coordinated Omission Problem}
Der Begriff \verb|Coordinated Omission Problem| wurde von Gil Tene, CTO und Mitgründer von Azul Systems, um 2012 geprägt.
Koordinierte Auslassung beschreibt in diesem Kontext das Problem, wenn ein Messsystem sich mit dem zu messenden System versehentlich so koordiniert,
dass es vermieden wird Ausreißer zu messen.

Viele Lastgeneratoren (load generator) berechnen die Latenz für eine Anfrage als die vergangene Zeit zwischen dem Senden des ersten Bytes einer Anfrage
bis zum Erhalt der kompletten Antwort. Während dieses Modell die tatsächliche Bearbeitungszeit individueller Anfragen korrekt misst,
liegt dabei ein starker koordinierter Auslassungseffekt vor,
wodurch die meisten Artefakte mit hoher Latenz, die der gemessene Server aufweist, ignoriert werden.
Da jede Verbindung erst anfängt eine neue Anfrage zu senden, nachdem eine Antwort bezüglich der vorherigen Anfrage erhalten wurde,
resultieren Antworten mit hoher Latenz darin, dass der Lastgenerator in einem bestimmten Zeitintervall weniger Anfragen an den Server schickt als in einer
Phase niedriger Latenz, da die weiteren Anfragen alle verzögert werden. Ähnlich wie bei \verb|Event Loops| \textit{blockieren}
Anfragen mit hoher Latenz also das Absenden weiterer Anfragen.
Dadurch koordiniert der Lastgenerator sich unbeabsichtigt mit dem Server um weitere Messungen während Phasen hoher Latenz zu vermeiden, da die Last die der Server
in dieser Phase abzuarbeiten hat deutlich geringer ist als bei niedriger Latenz. Das Hauptproblem ist also, dass die Last die der Server empfängt
nicht durchgehend \verb|konstant| ist, sondern von der Antwortszeit des Servers abhängt \parencite{mci/Friedrich2017}.
\newline\newline
\verb|Wrk2|, dessen Author auch Gil Tene ist, umgeht das \verb|Coordinated Omission Problem| in dem es eine konstante Durchsatzlast (als Befehlsargument) mit
einer Latenzmessung, die den beabsichtigten konstanten Durchsatz berücksichtigt, kombiniert. Anstatt dabei die Antwortlatenz ab dem Zeitpunkt zu messen,
zu dem die tatsächliche Übertragung einer Anfrage aufgetreten ist, misst wrk2 die Antwortlatenz ab dem Zeitpunkt, zu dem die Übertragung,
gemäß dem für den Durchlauf konfigurierten konstanten Durchsatz, hätte erfolgen \textit{sollen} bis zum Erhalt der vollständigen Antwort\parencite{Wrk2}.

Pro Test (siehe Anfang des Kapitels \ref{section:vergleich_reaktiv_imperativ}) werden Benchmarks für eine ganze Reihe an \textit{workloads} gemessen.
Jede \textit{workload} wird sekündlich über einen Zeitraum von 60 Sekunden über 100 offene HTTP-Verbindungen an den Server-Host übermittelt.
In den Tests nutzt \verb|wrk2| für das Generieren und Übermitteln der \textit{workload}, sowie das Messen der Antwortszeit
4 Threads.
\newline\newline
Damit der Anwendungscode des angesteuerten HTTP-Endpunkts durch den JIT-Compiler der JVM (siehe Absatz \verb|Quarkus und native image| in Kapitel
\ref{subsubsec:frameworks}) optimiert wird, findet pro \textit{workload} vor der eigentlichen Mess-Phase eine identische Warmup-Phase statt.

Listing \ref*{lst:generateLoad} zeigt den Aufruf von \verb|wrk2| mit den beschriebenen Parametern in der Warmup- und Mess-Phase,
\verb|${RUN_RATE}| enthält dabei die \textit{workload}.
\footnote{Das manuelle Kompilieren des Quellcodes von wrk2 produziert, wie wrk auch, ein executable namens wrk}

\begin{lstlisting}[caption=Auszug des qDup Skripts generate load, captionpos=b, label=lst:generateLoad]
- signal: ${{RUNTIME.name}}-${{RUN_RATE}}-WARM-UP-START
- sh: wrk -t 4 -c 100 -d 60s -R ${{RUN_RATE}} ${{TEST_DYNAMIC_ENDPOINT}} > ${{CLIENT_FILE_PATH}}/output/${{RUNTIME.name}}-${{RUN_RATE}}-WARM-UP.wrk2.out
- signal: ${{RUNTIME.name}}-${{RUN_RATE}}-WARM-UP-END
- sh: sleep 5s
- signal: ${{RUNTIME.name}}-${{RUN_RATE}}-MEASURE-START
- sh: wrk -t 4 -c 100 -d 60s -R ${{RUN_RATE}} --latency ${{TEST_DYNAMIC_ENDPOINT}} > ${{CLIENT_FILE_PATH}}/output/${{RUNTIME.name}}-${{RUN_RATE}}-MEASURE.wrk2.out
- signal: ${{RUNTIME.name}}-${{RUN_RATE}}-MEASURE-END
   \end{lstlisting}

Die Ausgabe von wrk2 enthält Informationen zur \Gls{latenz}\footnote{Pro verwendetem Thread und Gesamt},
zum \Gls{durchsatz} und der \Gls{perzentile}(*) der \Gls{latenz}, welches durch ein \Gls{hdrHistogramm} dargestellt wird.
Listing \ref*{lst:wrk-listing} zeigt die umgeleitete Ausgabe von \textit{wrk} ohne die genaue Darstellung der Perzentile.

\begin{lstlisting}[caption=Beispiel für Ausgabe von wrk,captionpos=b, label=lst:wrk-listing]
Running 1m test @ http://erik-pc.local:8080/greeting/Bob
4 threads and 100 connections
Thread calibration: mean lat.: 310.434ms, rate sampling interval: 1047ms
Thread calibration: mean lat.: 330.365ms, rate sampling interval: 1127ms
Thread calibration: mean lat.: 298.671ms, rate sampling interval: 994ms
Thread calibration: mean lat.: 333.465ms, rate sampling interval: 1123ms
Thread Stats   Avg      Stdev     Max   +/- Stdev
	Latency     1.76s   738.93ms   4.12s    62.98%
	Req/Sec    28.58k   633.82    30.09k    66.49%
6839722 requests in 1.00m, 476.17MB read
Requests/sec: 113929.77
Transfer/sec:      7.93MB
\end{lstlisting}\footnote{Die Resultate der 5 Testreihen sind auch im Quellcodeverzeichnis unter \textit{\/results} zu finden}

Bevor die Warmup-Phase und die Belastungs-Phase vom Client-Host ausgeführt werden, wird dem Server-Host signalisiert, dass
er das Skript \textit{capture platform stats} ausführen soll.
In diesem Skript wird die Observation des Anwendungs-Prozesses durch das Kommandozeilenprogramm \verb|top| gestartet.
\verb|Top| wird dabei im Batch-Modus gestartet mit einer Wiederholrate von einer Sekunde.

Die Prozess-Zeile der Ausgabe von \verb|top| enthält eine Vielzahl an Informationen zu dem beobachteten Prozess, von besonderem
Interesse sind hierbei die CPU-Auslastung und der verwendete Arbeitsspeicher des Prozesses. \parencite{linuxTopManual}

\begin{lstlisting}[language=sh, caption=Auszug des qDup Skripts capture-platform-stats, captionpos=b]
- wait-for: ${{RUNTIME.name}}-${{RUN_RATE}}-WARM-UP-START
- sh: top -b  -d 1 -p ${{RUN.JAVA_APP_PID}} | grep java > ${{SERVER_FILE_PATH}}/output/${{RUNTIME.name}}-${{RUN_RATE}}-WARM-UP-top.out &
- sh: export TOP_PID=$!
- wait-for: ${{RUNTIME.name}}-${{RUN_RATE}}-WARM-UP-END
- sh: kill -9 $TOP_PID
- wait-for: ${{RUNTIME.name}}-${{RUN_RATE}}-MEASURE-START
- sh: top -b  -d 1 -p ${{RUN.JAVA_APP_PID}} | grep java > ${{SERVER_FILE_PATH}}/output/${{RUNTIME.name}}-${{RUN_RATE}}-MEASURE-top.out &
- sh: export TOP_PID=$!
- wait-for: ${{RUNTIME.name}}-${{RUN_RATE}}-MEASURE-END
- sh: kill -9 $TOP_PID
  \end{lstlisting}

Im letzten Schritt werden alle Ausgaben über SSH vom Client- und Server-Host auf den User-Host der das qDup Skript ausgeführt hat kopiert.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Testaufbau}
    \caption{Testaufbau}
\end{figure}

In einem Bash-Skript werden anschließend die Ausgaben von \verb|top| und \verb|wrk| für jede einzelne \verb|workload| eines Tests
über ein Java-Skript, das mit dem Tool \textit{JBang} ausgeführt wird \footnote{JBang erlaubt das direkte Ausführen von .java Dateien},
eingelesen, analysiert und jeweils der Durchschnitt, das Minimum und das Maximum des Durchsatzes, Speicherverbrauches und CPU-Auslastung pro Last ermittelt.
Diese werden dann für die visuelle Darstellung in eine \verb|.json|-Datei geschrieben.
Zu guter Letzt werden die aufbereiteten Daten durch die Node.js-Bibliothek \textit{d3node-linechart} als Liniendiagramme visuell dargestellt.

\subsection{Test: Statische Daten}
\label{section:statische_daten}
Im Folgenden werden die Testresultate der 2. Testreihe dargestellt und erläutert.
Die Ergebnisse aller Testreihen können im Projektverzeichnis unter \verb|results/data| und \verb|results/graphs| eingesehen werden.
Der Lasttest mit statischen Daten wird ohne Datenbankanbindung durchgeführt und der angesteuerte Endpunkt \verb|/greeting/{name}| gibt bei beiden Anwendungen
jeweils einen statischen String zurück. Wie bereits zu Beginn des Kapitels erwähnt, wird jede Anwendung sowohl im \verb|JVM mode|, als auch im
\verb|native mode| getestet.
Die qDup-Skripte befinden sich im Projektverzeichnis im Verzeichnis \verb|scripts/benchmark-jvm-static.yaml| und
\verb|scripts/benchmark-native-static.yaml|.

\subsubsection{JVM mode}
Quarkus IO-Thread 1349.ms
Quarkus Worker-Pool 1514.6 ms

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{run2/jvm-static/mean-response-vs-throughput}
    \caption{Quarkus HTTP-Schicht \parencite{QuarkusReactiveRoutes}}
    \label{fig:static_mean_response}
\end{figure}

TODO Welche Perzentile
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{run2/jvm-static/mean-rss-vs-throughput}
    \caption{Quarkus HTTP-Schicht \parencite{QuarkusReactiveRoutes}}
    \label{fig:static_mean_rss}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{run2/jvm-static/average-cpu-vs-throughput}
    \caption{Quarkus HTTP-Schicht \parencite{QuarkusReactiveRoutes}}
    \label{fig:static_avg_cpu}
\end{figure}

//TODO: anmerken das werte nur bis zum umschwenkpunkt interessant sind konkret also nicht bspw. max rss (weil dieser bei 135k req/sec auch stark steigt)
// sondern lediglich bis 135k req/seq: worker thread : max req/sec 48k, io thread max req/sec 135k
\begin{table}[ht!]
    \centering
    \begin{tabular}{| c | c | c | c |}
        \hline
        Run 2 - JVM Static                    & Blockierend      & Reaktiv                   & Verhältnis \\
        \hline
        Mean Start Time to First Request (ms) & Resteasy         & Resteasy Reactive         &            \\
        \hline
        Max RSS (MB)                          & Resteasy-Jackson & Resteasy-Reactive-Jackson &            \\
        \hline
        Max Throughput (req/sec)              & JDBC-Postgresql  & Reactive-Pg-Client        &            \\
        \hline
        Max Req/Sec/MB                        & Hibernate-ORM    & Hibernate-Reactive        &            \\
        \hline
        CPU Auslastung 100\%                  & Hibernate-ORM    & Hibernate-Reactive        &            \\
        (req/sec)
    \end{tabular}
    \caption{Tabelle mit den Abhängigkeiten beider Applikationen}
    \label{table:static_measurement_results}
\end{table}

\subsubsection{native mode}
//startzeiten
//Speicherverbrauches
//cpu Auslastung
//durchsatz
\subsection{Test: Datenbankzugriffe}
\label{section:datenbankzugriffe}
Im Folgenden werden die Testresultate der 2. Testreihe dargestellt und erläutert.
Die Ergebnisse der anderen Testreihen können im Projektverzeichnis unter \verb|results/data| und \verb|results/graphs| eingesehen werden.
Der Lasttest mit dynamischen Daten wird mit Datenbankanbindung durchgeführt und der angesteuerte Endpunkt \verb|/fruits| gibt bei beiden Anwendungen
jeweils alle Elemente der Tabelle \textit{fruits} zurück. Wie bereits zu Beginn des Kapitels erwähnt, wird jede Anwendung sowohl im \verb|JVM mode|, als auch im
\verb|native mode| getestet, die qDup-Skripte befinden sich im Projektverzeichnis im Verzeichnis \verb|scripts/benchmark-jvm-db.yaml| und
\verb|scripts/benchmark-native-db.yaml|.

\subsubsection{JVM mode}
//startzeiten
//Speicherverbrauches
//cpu Auslastung
//durchsatz
\subsubsection{native mode}
//startzeiten
//Speicherverbrauches
//cpu Auslastung
//durchsatz

\subsection{Auswertung}
//wie könnte ergebnis aussehen mit komplexeren queries
//ressourcenbedarf von reaktiver anwendung könnte noch weiter gesenkt werden, allerdings wird der worker thread pool von vert.x aus
kompatibilätsgründen zu blocking i/o genutzt

//native anwendungen können (noch) nicht den durchsatz von jvm anwendungen erreichen (ist aber theoretisch laut entwicklern möglich), da
viele laufzeit optimierungen wegfallen
//in startzeiten und ressourcenverbrauch native anwendungen allerdings überlegen
//reaktive anwendungen lohnen sich erst ab bestimmter req/sec
//könnte verändert werden durch: bessere hardware, anpassen der worker thread pool größe und event loop thread pool größe
//,weglassen von vert.x für den test der blockierenden anwendung da dispatching von io thread auf blocking thread auch kosten verursacht, Quarkus
nutzut allerdings immer vert.x, verändern der gepoolten datenbank verbindungen, komplexere queries (verhältnis der größenordnungen wäre aber gleich)


//eher fazit
und erfordern das alle komponenten reaktiv sind (also auch alle library hesteller)
//lösungen wie project loom deutlich komfortabler in  zukunft
\label{section:auswertung}