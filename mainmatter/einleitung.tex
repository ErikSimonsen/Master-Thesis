% !TEX root = main.tex

\section{Einleitung}
\label{sec:einleitung}

\subsection{Motivation}
\label{subsec:motivation}

In der heutigen globalisierten Geschäftswelt werden Videokonferenzen von Unternehmen, Bildungseinrichtungen und öffentlichen Institutionen immer häufiger eingesetzt.
Gerade in der aktuellen Corona-Krise erleichtern sie als virtuelles Kommunikationstool den Arbeitsalltag im Home-Office und eröffnen eine flexible
Form der Teamarbeit und der Lehre.
Mitarbeiter, Dozenten und Studenten sind nicht länger an einen gemeinsamen physischen Ort gebunden, sondern können
standortübergreifend in den direkten Informationsaustausch treten und per Audio- und Videoübertragung effizient zusammenarbeiten.
Damit das jedoch problemlos möglich ist, bedarf es entsprechender Videokonferenzsysteme, welche die technischen Voraussetzungen dafür erst schaffen.

Der überwiegende Teil der populären Systeme benötigen einen Client in Form einer Desktopanwendung und nutzen proprietäre Kommunikationsprotokolle und Dateiformate.
Das Ziel dieser Arbeit ist die Realisierung eines groben Prototypen eines web- bzw. browserbasierten Konferenzsystems, welches ausschließlich
auf offenen Standards und Technologien basiert.
Dabei werden zudem die Aspekte der Skalierbarkeit (Anzahl der Teilnehmer) und der Komplexität betrachtet.

Zu Beginn werden die zwei gängigen Ansätze der Datenübertragung (HTTP-basiert, WebRTC) im Live- und On-Demand Streaming erläutert
und bezüglich des Anwendungskontext miteinander verglichen.
Daraufhin werden die einzelnen Komponenten und Technologien, dessen Funktionsweisen und konkrete Implementierung erklärt,
sowie Probleme und Limitierungen aufgezeigt.

\subsection{HTTP-basiertes Streaming}
\label{subsec:HttpBasiertesLiveStreaming}
Beim HTTP-Streaming werden die darzustellenden Media-Inhalte über HTTP durch einen Webserver zur Verfügung gestellt.
Dabei werden die Inhalte in eine Vielzahl an kleinen Datei-Segmenten zerlegt, welche jeweils einen Teil der Gesamtdauer enthalten.
Die Segmente werden mehrfach, in unterschiedlichen Bitraten kodiert, auf dem Server hinterlegt.
Dadurch kann der Client jederzeit das Segment auswählen das mit der derzeitigen Bandbreite, innerhalb der gegebenen Zeitgrenzen, vollständig übertragen werden kann,
um somit ein sog.
Buffering\footnote{Ein Stoppen der Wiedergabe bis die nächsten Inhalte geladen sind} bei dynamischen Netzwerkbedingungen weitestgehend zu verhindern.
Diese Technik wird als \textit{adaptive bitrate streaming} bezeichnet\parencite{Sodagar2011}\parencite{Sodagar2012Paper}.
MPEG-Dash ist der erste internationale Standard im Bereich des \textit{bitrate adaptive streaming}\parencite{MPEG2011}.

Informationen über die Segmente wie Dauer, URI, Reihenfolge und Bitraten werden in einer \textit{media presentation description, MDP} festgehalten und zu Beginn dem
Client übermittelt.\parencite[Seite 3]{Pantos2020}
Dieser kann dann über die URI die Segmente nacheinander vom Server abrufen.
Das Format und die Struktur der \textit{MDP} sowie die genauen Implementierungsdetails (Segmentierung, Dateiformate, Videokompressionsverfahren) unterscheiden
sich bei den populären HTTP-basierten Streaming-Protokollen, so wird die MPD bei HLS als Media Playlist bezeichnet\parencite{Pantos2020}.
So gibt es unter Anderem:
\begin{itemize}
    \item Dynamic Adaptive Streaming over HTTP (MPEG-DASH) von MPEG
    \item HTTP Live Streaming [HLS] von Apple
    \item Microsoft Smooth Streaming (MSS) von Microsoft
\end{itemize}

\subsection{WebRTC}
\label{subsec:WebRTC}
Bei WebRTC(Web Real-Time Communication) handelt es sich um einen offenen Standard, der vom World Wide Web Consortium (W3C) standardisiert wird.
Maßgebliche Unterstützung und Entwicklungsarbeit erfolgt dabei von großen Browser-Herstellern wie Google Inc, Mozilla Foundation und Opera Software\parencite[Siehe Editors]{W3WebRTC}.
Der Standard umfasst mehrere Programmierschnittstellen und Kommunikationsprotokolle, welche es Browsern ermöglichen auf bestimmte
Hardware als Medienquelle zuzugreifen, und dessen Video-, Sprach- oder generische Daten mit Browsern auf anderen Rechnern (\textit{peers}) in Echtzeit bidirektional auszutauschen.
Bevor der Datenaustausch erfolgen kann, muss allerdings zuerst eine Verbindung zwischen zwei (oder mehreren) \textit{peers} über einen
zentralen Server(\textit{signaling-server}) hergestellt werden
\footnote{Dieser Vorgang wird als \textit{signaling} bezeichnet und ist nicht Teil des WebRTC-Standards \parencite{WebRTC2020GS}}.
Die Technologien, welche WebRTC umfasst, sind in allen populären Browsern als Javascript-APIs implementiert\parencite[Abschnitt \textit{Signaling}]{WebRTC2020}.
Die wesentlichen Komponenten sind:

\begin{itemize}
    \item \textit{getUserMedia} Gewährt Zugriff auf Audio- und Videoquellen (Webcam, Mikrofon)\parencite[Abschnitt 9]{W3WebRTC}
    \item \textit{RTCPeerConnection} Ermöglicht Austausch der Daten zwischen \textit{peers}\parencite[Abschnitt 4.4]{W3WebRTC}.
    Kümmert sich um die \textit{peer-to-peer} Kommunikation, Signalverarbeitung, Kodierung- und Dekodierung,sowie Sicherheit der Kommunikation (Verschlüsselung der Daten)
    \item \textit{RTCDataChannel} Erlaubt die bidirektionale Kommunikation von beliebigen Daten zwischen \textit{peers} mit sehr niedriger Latenz\parencite[Abschnitt 6]{W3WebRTC}.
\end{itemize}